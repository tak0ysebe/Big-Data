{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>these were so go  it surprised even me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>my sister in law made these for us at a family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
       "      <td>this is based on a french recipe but i changed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
       "      <td>this is a traditional fresh plum cake  thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
       "      <td>this is a traditional late summer early fall s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>zydeco soup</td>\n",
       "      <td>this is a delicious soup that i originally fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>cookies by design   cookies on a stick</td>\n",
       "      <td>i ve heard of the  cookies by design  company ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  \\\n",
       "0             george s at the cove  black bean soup   \n",
       "1                healthy for them  yogurt popsicles   \n",
       "2                      i can t believe it s spinach   \n",
       "3                              italian  gut busters   \n",
       "4          love is in the air  beef fondue   sauces   \n",
       "...                                             ...   \n",
       "29995  zurie s holey rustic olive and cheddar bread   \n",
       "29996          zwetschgenkuchen  bavarian plum cake   \n",
       "29997   zwiebelkuchen   southwest german onion cake   \n",
       "29998                                   zydeco soup   \n",
       "29999        cookies by design   cookies on a stick   \n",
       "\n",
       "                               preprocessed_descriptions  \n",
       "0      an original recipe created by chef scott meska...  \n",
       "1      my children and their friends ask for my homem...  \n",
       "2                these were so go  it surprised even me   \n",
       "3      my sister in law made these for us at a family...  \n",
       "4      i think a fondue is a very romantic casual din...  \n",
       "...                                                  ...  \n",
       "29995  this is based on a french recipe but i changed...  \n",
       "29996  this is a traditional fresh plum cake  thought...  \n",
       "29997  this is a traditional late summer early fall s...  \n",
       "29998  this is a delicious soup that i originally fou...  \n",
       "29999  i ve heard of the  cookies by design  company ...  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed_descriptions.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23037"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words1 = set() #мнодество удаляет повторы\n",
    "for i in df['preprocessed_descriptions'].values:\n",
    "    words1.update(word_tokenize(str(i).lower())) \n",
    "#используем update, а не add, т к добавляем не один элемент, а список!\n",
    "a = list(words1) # в массив\n",
    "words = set()\n",
    "for x in a:\n",
    "    if x.isalpha(): # проверка на слово \n",
    "        words.add(x)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние между 'fulls' и 'wait': 5\n",
      "Расстояние между 'engaged' и 'pommeau': 7\n",
      "Расстояние между 'tamed' и 'yuuuuuuuuummmmm': 14\n",
      "Расстояние между 'tavern' и 'hasty': 5\n",
      "Расстояние между 'paint' и 'dariole': 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sibir\\AppData\\Local\\Temp\\ipykernel_10580\\531333538.py:2: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  random_pairs = random.sample(words, k=10)  # Выбираем 10 случайных слов из unique_words\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_pairs = random.sample(words, k=10)  # Выбираем 10 случайных слов из unique_words\n",
    "for i in range(0, len(random_pairs), 2):\n",
    "    word1 = random_pairs[i]\n",
    "    word2 = random_pairs[i + 1]\n",
    "    edit_distance = nltk.edit_distance(word1, word2) # расстояние Левенштейна\n",
    "    print(f\"Расстояние между '{word1}' и '{word2}': {edit_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(word, k):\n",
    "    dis = {} # Словарь для хранения расстояний между словами и заданным словом\n",
    "    for i in words:\n",
    "        r = nltk.edit_distance(word, i) # Вычисление расстояния Левенштейна\n",
    "        dis[i] = r\n",
    "    #print(dis)\n",
    "    # ключ - слово, значение - расстояние Левеншиейна r\n",
    "    # через get достаются значения из словаря dis, key - по какому принципу мы сортируем словарь\n",
    "    sor = sorted(dis, key=dis.get)[:k]\n",
    "    # Сортировка слов по расстоянию и выбор k ближайших слов\n",
    "    return f\"Ближайшие {k} слова к '{word}': {sor}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ближайшие 4 слова к 'parm': ['parm', 'palm', 'farm', 'para']\n"
     ]
    }
   ],
   "source": [
    "print(find('parm', 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sibir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sibir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whoever</th>\n",
       "      <td>whoever</td>\n",
       "      <td>whoever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serves</th>\n",
       "      <td>serv</td>\n",
       "      <td>serf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parmenter</th>\n",
       "      <td>parment</td>\n",
       "      <td>parmenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tennesse</th>\n",
       "      <td>tenness</td>\n",
       "      <td>tennesse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overwhelmingly</th>\n",
       "      <td>overwhelm</td>\n",
       "      <td>overwhelmingly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ferrero</th>\n",
       "      <td>ferrero</td>\n",
       "      <td>ferrero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ususally</th>\n",
       "      <td>usus</td>\n",
       "      <td>ususally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wobbly</th>\n",
       "      <td>wobbl</td>\n",
       "      <td>wobbly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mangetsu</th>\n",
       "      <td>mangetsu</td>\n",
       "      <td>mangetsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmmmmmoe</th>\n",
       "      <td>mmmmmmoe</td>\n",
       "      <td>mmmmmmoe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23037 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               stemmed_word normalized_word\n",
       "word                                       \n",
       "whoever             whoever         whoever\n",
       "serves                 serv            serf\n",
       "parmenter           parment       parmenter\n",
       "tennesse            tenness        tennesse\n",
       "overwhelmingly    overwhelm  overwhelmingly\n",
       "...                     ...             ...\n",
       "ferrero             ferrero         ferrero\n",
       "ususally               usus        ususally\n",
       "wobbly                wobbl          wobbly\n",
       "mangetsu           mangetsu        mangetsu\n",
       "mmmmmmoe           mmmmmmoe        mmmmmmoe\n",
       "\n",
       "[23037 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# в таблицу можно добавлять только массивы\n",
    "words = list(words)\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "dt = pd.DataFrame({'word': words, 'stemmed_word': [stemmer.stem(i) for i in words], \n",
    "                      'normalized_word': [lemmatizer.lemmatize(i) for i in words]})\n",
    "dt.set_index('word')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sibir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1104518"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#словарь: слово + кол-во вхождений\n",
    "counter = Counter()\n",
    "\n",
    "for i in df['preprocessed_descriptions']:\n",
    "    counter.update(word_tokenize(str(i).lower()))\n",
    "#print(counter)\n",
    "n_words_old = sum(counter.values())\n",
    "n_words_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 40413),\n",
       " ('a', 35131),\n",
       " ('and', 30585),\n",
       " ('i', 27945),\n",
       " ('this', 27181),\n",
       " ('to', 23598),\n",
       " ('it', 23300),\n",
       " ('is', 20306),\n",
       " ('of', 18405),\n",
       " ('for', 16023)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.09755748661407%\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "keys = list(counter.keys())\n",
    "for i in keys:\n",
    "    if i in en_stopwords:\n",
    "        counter.pop(i)\n",
    "print(str(100 - sum(counter.values()) / n_words_old * 100) + '%') # достаем значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22311203, 0.        , 0.22311203, 0.        , 0.44826218,\n",
       "       0.22311203, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.22311203, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.22311203, 0.        , 0.        ,\n",
       "       0.22311203, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.14942073, 0.        , 0.        ,\n",
       "       0.22311203, 0.        , 0.        , 0.        , 0.18000538,\n",
       "       0.18000538, 0.        , 0.        , 0.22311203, 0.        ,\n",
       "       0.        , 0.22311203, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18000538,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.22311203,\n",
       "       0.        , 0.        , 0.22311203, 0.        , 0.22311203,\n",
       "       0.        , 0.        , 0.18000538, 0.        , 0.        ,\n",
       "       0.22311203, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "sample = df.sample(5)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(sample.preprocessed_descriptions.values).toarray() \n",
    "#приводим в векторый вид, записываем векорный вид в матрицу\n",
    "\n",
    "vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Рецепт 1</th>\n",
       "      <th>Рецепт 2</th>\n",
       "      <th>Рецепт 3</th>\n",
       "      <th>Рецепт 4</th>\n",
       "      <th>Рецепт 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Рецепт 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.966728</td>\n",
       "      <td>0.874754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.876163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Рецепт 2</th>\n",
       "      <td>0.966728</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Рецепт 3</th>\n",
       "      <td>0.874754</td>\n",
       "      <td>0.94748</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937014</td>\n",
       "      <td>0.733862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Рецепт 4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.937014</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Рецепт 5</th>\n",
       "      <td>0.876163</td>\n",
       "      <td>0.862501</td>\n",
       "      <td>0.733862</td>\n",
       "      <td>0.867126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Рецепт 1  Рецепт 2  Рецепт 3  Рецепт 4  Рецепт 5\n",
       "Рецепт 1         0  0.966728  0.874754       1.0  0.876163\n",
       "Рецепт 2  0.966728         0   0.94748       1.0  0.862501\n",
       "Рецепт 3  0.874754   0.94748         0  0.937014  0.733862\n",
       "Рецепт 4       1.0       1.0  0.937014         0  0.867126\n",
       "Рецепт 5  0.876163  0.862501  0.733862  0.867126         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "matrix = pd.DataFrame(index=range(5), columns=range(5) # пустой DataFrame\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(i, 5):\n",
    "        similarity = cosine(vectors[i], vectors[j])\n",
    "        matrix.loc[i, j] = similarity\n",
    "        matrix.loc[j, i] = similarity\n",
    "\n",
    "\n",
    "matrix.columns = ['Рецепт ' + str(i+1) for i in range(5)]\n",
    "matrix.index = ['Рецепт ' + str(i+1) for i in range(5)]\n",
    "\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем меньше значение, тем более схожи слова(т е 0 означает 100 % совпадение слов)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
